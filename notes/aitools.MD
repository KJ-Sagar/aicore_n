## AI tools and Open Source Libraries

Open Source Python Libraries
Github [repo search readme](https://docs.github.com/en/enterprise-server@3.4/search-github/getting-started-with-searching-on-github/understanding-the-search-syntax) ---> [Github](https://github.com/search?l=Python&q=stars%3A%3E1000&type=Repositories).

Here is a list of all python libraries beyond 2k stars, updated in 25/09/2022




PYTHON LIBRARIES:


<table style="width:100%" >
<tr>
<th>
<p>Heading
</p>
</th>
<th>
<p>Libraries
</p></th>
</tr>
<tr>

<td>
Python 
</td>

<td>

+ [awesome-python](https://github.com/vinta/awesome-python#readme), [The Algorithms/Python](https://github.com/TheAlgorithms/Python), [awesome-ml/python](https://github.com/josephmisiti/awesome-machine-learning#python), [ctci](https://github.com/careercup/CtCI-6th-Edition-Python), [python pattern](https://github.com/faif/python-patterns), [py-cheatsheet](https://github.com/gto76/python-cheatsheet), [py-examples](https://github.com/geekcomputers/Python),
[interactive-coding-challenges](https://github.com/donnemartin/interactive-coding-challenges), [python-robotics](https://github.com/AtsushiSakai/PythonRobotics), [data-structure & algorithm](https://github.com/keon/algorithms), [pysheet](https://github.com/crazyguitar/pysheeet), [cookiecutter](https://github.com/cookiecutter/cookiecutter).
</td>

</tr>


<tr>

<td>
pylibs
</td>

<td>

+ [python-fire](https://github.com/google/python-fire), [faker](https://github.com/joke2k/faker) & [mimesis](https://github.com/lk-geimfari/mimesis), [sh](https://github.com/amoffat/sh), [marshmallow](https://github.com/marshmallow-code/marshmallow), [boltons](https://github.com/mahmoud/boltons), [py-github](https://github.com/PyGithub/PyGithub), [py-dotenv](https://github.com/theskumar/python-dotenv), [jedi](https://github.com/davidhalter/jedi), [jedi-vim](https://github.com/davidhalter/jedi-vim), [setup.py](https://github.com/navdeep-G/setup.py), [trio](https://github.com/python-trio/trio), [pycodestyle](https://github.com/PyCQA/pycodestyle), [pyinstrument](https://github.com/joerick/pyinstrument), [pathplanning](https://github.com/zhm-real/PathPlanning), [pidcat](https://github.com/JakeWharton/pidcat), [augly](https://github.com/facebookresearch/AugLy) (data aug), [pipreqs](https://github.com/bndr/pipreqs) ( or pip
freeze > req.txt), [apscheduler](https://github.com/agronholm/apscheduler) & [huey](https://github.com/coleifer/huey) (task schedule), [attrs](https://github.com/python-attrs/attrs), [bandit](https://github.com/PyCQA/bandit), [tablib](https://github.com/jazzband/tablib), [autopep8](https://github.com/hhatto/autopep8), [better_exception](https://github.com/Qix-/better-exceptions), [tenacity](https://github.com/jd/tenacity), [py-sorted-containers](https://github.com/grantjenks/python-sortedcontainers),
[viztracer](https://github.com/gaogaotiantian/viztracer), [memray](https://github.com/bloomberg/memray), [ryven](https://github.com/leon-thomm/Ryven), [black](https://github.com/psf/black), [monkeytype](https://github.com/Instagram/MonkeyType), [pytype](https://github.com/google/pytype), [vprof](https://github.com/nvdv/vprof), [cookie-cutter-py-package](https://github.com/audreyfeldroy/cookiecutter-pypackage), [coconut](https://github.com/evhub/coconut) (functional programming), [pampy](https://github.com/santinic/pampy).

</td>
</tr>


<tr>

<td>
essentials libraries
</td>

<td>

+ [numpy](https://github.com/numpy/numpy), [pandas](https://github.com/pandas-dev/pandas), [matplotlib](https://github.com/matplotlib/matplotlib), [scipy](https://github.com/scipy/scipy), [scikit-learn](https://github.com/scikit-learn/scikit-learn) | [blaze](https://github.com/blaze/blaze) (numpy, pandas for big data), [cupy](https://github.com/cupy/cupy) (NumPy & SciPy for GPU).
</td>
</tr>


<tr>

<td>
ml extra
</td>

<td>

+ [transfer learning](https://github.com/jindongwang/transferlearning#7datasets-and-benchmarks-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C), [docker-stacks](https://github.com/jupyter/docker-stacks), [hyper-opt](https://github.com/hyperopt/hyperopt), [feature-tools](https://github.com/alteryx/featuretools), [einops](https://github.com/arogozhnikov/einops), [cog](https://github.com/replicate/cog), [floydhub](https://github.com/floydhub/dl-docker), [FEAST](https://github.com/feast-dev/feast), [causal-ml](https://github.com/uber/causalml), [scikit-opt](https://github.com/guofei9987/scikit-opt), [anomaly detect](https://github.com/yzhao062/anomaly-detection-resources), [Bayesian Optimization](https://github.com/fmfn/BayesianOptimization).

</td>
</tr>

<tr>

<td>
tf / (PyTorch )
</td>

<td>

+ [tensorpack](https://github.com/tensorpack/tensorpack), [hub](https://github.com/tensorflow/hub) (transfer learning), [pyg-team](https://github.com/pyg-team/pytorch_geometric), [pretrained-models](https://github.com/Cadene/pretrained-models.pytorch), [minGPT](https://github.com/karpathy/minGPT), [tensorboardX](https://github.com/lanpa/tensorboardX), [pyro](https://github.com/pyro-ppl/pyro), [CNNviZ](https://github.com/utkuozbulak/pytorch-cnn-visualizations), [External Attention](https://github.com/xmu-xiaoma666/External-Attention-pytorch), [segmentation-models](https://github.com/qubvel/segmentation_models.pytorch), [torchdiffeq](https://github.com/rtqichen/torchdiffeq), [ignite](https://github.com/pytorch/ignite), [gpytorch](https://github.com/cornellius-gp/gpytorch), [catalyst](https://github.com/catalyst-team/catalyst) (for R&D), [big-graph](https://github.com/facebookresearch/PyTorch-BigGraph), [VAE](https://github.com/AntixK/PyTorch-VAE), [metaseq](https://github.com/facebookresearch/metaseq), [THOP](https://github.com/Lyken17/pytorch-OpCounter), [captum](https://github.com/pytorch/captum), [Imaginaire](https://github.com/NVlabs/imaginaire), [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt), [pytorch.summary()](https://github.com/sksq96/pytorch-summary), [person-reid](https://github.com/KaiyangZhou/deep-person-reid).
</td>
</tr>


<tr>

<td>
ML framework: 
</td>

<td>

+ [autogluon](https://github.com/awslabs/autogluon), [jax](https://github.com/google/jax), [sanic](https://github.com/sanic-org/sanic), [falcon](https://github.com/falconry/falcon), [ludwig](https://github.com/ludwig-ai/ludwig), [kedro](https://github.com/kedro-org/kedro), [trax](https://github.com/google/trax), [deepo](https://github.com/ufoym/deepo), [ivy](https://github.com/unifyai/ivy), [chainer](https://github.com/chainer/chainer), [sktime](https://github.com/alan-turing-institute/sktime) & [merlion](https://github.com/salesforce/Merlion) (time series), [pocketflow](https://github.com/Tencent/PocketFlow), [igel](https://github.com/nidhaloff/igel) (no code), [flax](https://github.com/google/flax).

</td>
</tr>

</table>

Reinforcement Learning libraries:

+ [baselines](https://github.com/openai/baselines), [gym](https://github.com/openai/gym), [mujoco](https://github.com/deepmind/mujoco), [tianshou](https://github.com/thu-ml/tianshou), [DRL-PyTorch](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch), [dm_control](https://github.com/deepmind/dm_control), [PARL](https://github.com/PaddlePaddle/PARL), [ReAgent tensorforce](https://github.com/facebookresearch/ReAgent).

MLOPs / Distributed ML libraries:

+ [horovod](https://github.com/horovod/horovod), [Deep Speed](https://github.com/microsoft/DeepSpeed), [modin](https://github.com/modin-project/modin), [bentoml](https://github.com/bentoml/BentoML), [apex](https://github.com/NVIDIA/apex), [dask](https://github.com/dask/dask), [colossal-AI](https://github.com/hpcaitech/ColossalAI), [composer](https://github.com/mosaicml/composer), [mlflow](https://github.com/mlflow/mlflow), [lightning](https://github.com/Lightning-AI/lightning), [airflow](https://github.com/apache/airflow), [deap](https://github.com/DEAP/deap) (distributed evolutionary algorithms), [ray](https://github.com/ray-project/ray), [mars](https://github.com/mars-project/mars), [tensorflowonspark](https://github.com/yahoo/TensorFlowOnSpark), [sonnet](https://github.com/deepmind/sonnet), [celery](https://github.com/celery/celery), [pandarallel](https://github.com/nalepae/pandarallel), [polyaxon](https://github.com/polyaxon/polyaxon), [hummingbird](https://github.com/microsoft/hummingbird), [nni](https://github.com/microsoft/nni) , [byteps](https://github.com/bytedance/byteps), [vaex](https://github.com/vaexio/vaex), [clearml](https://github.com/allegroai/clearml), [tvm](https://github.com/apache/tvm), [st2](https://github.com/StackStorm/st2), [jina](https://github.com/jina-ai/jina) , [accelerate](https://github.com/huggingface/accelerate).

Computer Vision / Visualization Libraries:

<table>
<tr>

<td>
CV Toolbox
</td>

<td>

+ [mmlab](https://github.com/open-mmlab/mmcv), [gluon-cv](https://github.com/dmlc/gluon-cv), [slowfast](https://github.com/facebookresearch/SlowFast), [grad-cam](https://github.com/jacobgil/pytorch-grad-cam).
 
</td>
</tr>


<tr>

<td>
Object Detection
</td>

<td>

+ [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX), [detr](https://github.com/facebookresearch/detr), [ImageAI](https://github.com/OlafenwaMoses/ImageAI#customprediction), [EfficientNet](https://github.com/lukemelas/EfficientNet-PyTorch), [CenterNet](https://github.com/xingyizhou/CenterNet), [frigate](https://github.com/blakeblackshear/frigate), [nanodet](https://github.com/RangiLyu/nanodet) (lightwight), [obj-detect-metric](https://github.com/rafaelpadilla/review_object_detection_metrics), [ConvNeXt](https://github.com/facebookresearch/ConvNeXt), [YoloV7](https://github.com/jinfagang/yolov7_d2), [ByteTrack](https://github.com/ifzhang/ByteTrack), [mmtracking](https://github.com/open-mmlab/mmtracking).
 
</td>
</tr>



<tr>

<td>
Text-to-Image 
</td>

<td>

+ [PyTorch] [DALL-E](https://github.com/lucidrains/DALLE-pytorch), [DALLE2](https://github.com/lucidrains/DALLE2-pytorch), [dalle-mini](https://github.com/borisdayma/dalle-mini), [stable diffusion](https://github.com/CompVis/stable-diffusion) ([lexica.art](https://lexica.art/)), [Imagen](https://github.com/lucidrains/imagen-pytorch), [stable diffusion_webui](https://github.com/sd-webui/stable-diffusion-webui).
 
</td>
</tr>



<tr>

<td>
Multilingual OCR &QR
</td>

<td>

+ [Paddle Paddle](https://github.com/PaddlePaddle/PaddleOCR), [EasyOCR](https://github.com/JaidedAI/EasyOCR), [amazing-qr](https://github.com/x-hw/amazing-qr), [OCR PDF](https://github.com/ocrmypdf/OCRmyPDF).
 
</td>
</tr>


<tr>

<td>
Image Augmentation
</td>

<td>

+  [imgaug](https://github.com/aleju/imgaug), [albumentations](https://github.com/albumentations-team/albumentations).
 
</td>
</tr>


<tr>

<td>
Upscale 
</td>

<td>

+ [video2x](https://github.com/k4yt3x/video2x).
 
</td>
</tr>


<tr>

<td>
Pose Detection
</td>

<td>

+ [alphapose](https://github.com/MVIG-SJTU/AlphaPose), [mmskeleton](https://github.com/open-mmlab/mmskeleton), [videopose3D](https://github.com/facebookresearch/VideoPose3D), [DeepLabCut](https://github.com/DeepLabCut/DeepLabCut).
 
</td>
</tr>


<tr>

<td>
Annotation tool 
</td>

<td>

+ [labelme](https://github.com/wkentaro/labelme), [labelmg](https://github.com/heartexlabs/labelImg), [label-studio](https://github.com/heartexlabs/label-studio).
 
</td>
</tr>


<tr>

<td>
Deep Fakes 
</td>

<td>

+ [DeepFaceLive](https://github.com/iperov/DeepFaceLive), [PaddleGAN](https://github.com/PaddlePaddle/PaddleGAN), [dot](https://github.com/sensity-ai/dot) ( deepfakes offensive toolkit).
 
</td>
</tr>


<tr>

<td>
Segmentation / Inpainting / Matting
</td>

<td>

+ [PaddleSeg](https://github.com/PaddlePaddle/PaddleSeg), [3D photo inpainting, video matting](https://github.com/vt-vl-lab/3d-photo-inpainting), [bg-matting-v2](https://github.com/PeterL1n/BackgroundMattingV2), [yolact](https://github.com/dbolya/yolact), [semantic seg](https://github.com/CSAILVision/semantic-segmentation-pytorch), [Super SloMo](https://github.com/avinashpaliwal/Super-SloMo).

 
</td>
</tr>


<tr>

<td>
Face Detection
</td>

<td>

+ [face.evoLVe](https://github.com/ZhaoJ9014/face.evoLVe), [InsightFace](https://github.com/deepinsight/insightface), [face-alignment](https://github.com/1adrianb/face-alignment), [PRNET](https://github.com/YadiraF/PRNet), [fawkes](https://github.com/Shawn-Shan/fawkes) (privacy preserving), [deepface](https://github.com/serengil/deepface), [howdy](https://github.com/boltgolt/howdy).

 
</td>
</tr>


<tr>

<td>
WebML
</td>

<td>

+ [gradio](https://github.com/gradio-app/gradio) (UI for ML model).
 
</td>
</tr>


<tr>

<td>
3D data processing & reconstruction
</td>

<td>

+ [Open3D](https://github.com/isl-org/Open3D), [meshroom](https://github.com/alicevision/meshroom), [PyTorch3D](https://github.com/facebookresearch/pytorch3d), [mmlab3d](https://github.com/open-mmlab/mmdetection3d), [OpenPCDet](https://github.com/open-mmlab/OpenPCDet), [OpenSfm](https://github.com/mapillary/OpenSfM), [kaolin](https://github.com/NVIDIAGameWorks/kaolin), [ODM](https://github.com/OpenDroneMap/ODM), [PointNet](https://github.com/charlesq34/pointnet), [3D-Resnets](https://github.com/kenshohara/3D-ResNets-PyTorch).
 
</td>
</tr>


<tr>

<td>
fun plugins
</td>

<td>

+ [avatarify-python](https://github.com/alievk/avatarify-python), [word cloud](https://github.com/amueller/word_cloud), [pywal](https://github.com/dylanaraps/pywal), [tiler](https://github.com/nuno-faria/tiler), [learning to see in dark](https://github.com/cchen156/Learning-to-See-in-the-Dark), [rembg](https://github.com/danielgatis/rembg), [imagededup](https://github.com/idealo/imagededup) (find duplicate images), [imutils](https://github.com/PyImageSearch/imutils) (image operations), [videogrep](https://github.com/antiboredom/videogrep), [NeRF](https://github.com/yenchenlin/nerf-pytorch), [LEGOFY](https://github.com/JuanPotato/Legofy), [discoart](https://github.com/jina-ai/discoart), [image/analogies](https://github.com/awentzonline/image-analogies).
 
</td>
</tr>

<tr>

<td>
Big Data visualization
</td>

<td>

+ [visdom](https://github.com/fossasia/visdom) (LIVE experiments), [redash](https://github.com/getredash/redash) (from Datalake), [great_expectations](https://github.com/great-expectations/great_expectations), [folium](https://github.com/python-visualization/folium), [visidata](https://github.com/saulpw/visidata), [lux](https://github.com/lux-org/lux) (pandas dataframe).
 
</td>
</tr>


<tr>

<td>
Extra
</td>

<td>

+ [diagrams](https://github.com/mingrammer/diagrams) (vis cloud architecture),  [openpilot](https://github.com/commaai/openpilot), [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN), [pifuhd](https://github.com/facebookresearch/pifuhd), [pix2pixhd](https://github.com/NVIDIA/pix2pixHD), [Neural-style](https://github.com/anishathalye/neural-style), [tensorflow-GAN](https://github.com/hwalsuklee/tensorflow-generative-model-collections),  [eht-imaging](https://github.com/NVIDIA/pix2pixHD), [efficient-ai-backbone](https://github.com/huawei-noah/Efficient-AI-Backbones), [bandai-namco motion dataset](https://github.com/BandaiNamcoResearchInc/Bandai-Namco-Research-Motiondataset), [MONAI](https://github.com/Project-MONAI/MONAI).

 
</td>
</tr>

</table>

Natural Language Processing (NLP) libraries:

<table>
<tr>

<th>Heading</th>
<th>Libraries</th>

</tr>
<tr>

<td>NLP toolkit</td>
<td>

+ [funNLP](https://github.com/fighting41love/funNLP), [NLP Progress](https://github.com/sebastianruder/NLP-progress), [flair](https://github.com/flairNLP/flair), [pytext](https://github.com/facebookresearch/pytext), [allenNLP](https://github.com/allenai/allennlp), [nltk](https://github.com/nltk/nltk), [haystack](https://github.com/deepset-ai/haystack), [ParlAI](https://github.com/facebookresearch/ParlAI), [fairseq](https://github.com/facebookresearch/fairseq), [ERNIE](https://github.com/PaddlePaddle/ERNIE), [stanza](https://github.com/stanfordnlp/stanza), [speech brain](https://github.com/speechbrain/speechbrain), [OpenNRE](https://github.com/thunlp/OpenNRE).

</td>

</tr>


<tr>

<td>
audio analysis
</td>
<td>

+ [PyAudioAnalysis](https://github.com/tyiannak/pyAudioAnalysis), [espnet](https://github.com/espnet/espnet) (end2endspeech processing), [librosa](https://github.com/librosa/librosa)

</td>

</tr>


<tr>

<td>
chatbot
</td>
<td>

+ [errbot](https://github.com/errbotio/errbot), [wav2lip](https://github.com/Rudrabha/Wav2Lip) (speech2lip)

</td>

</tr>


<tr>

<td>text2speech</td>
<td>

+ [TTS](https://github.com/coqui-ai/TTS)
</td>

</tr>


<tr>

<td>time series </td>
<td>

+ [darts](https://github.com/unit8co/darts), [kats](https://github.com/facebookresearch/Kats), [prophet](https://facebook.github.io/prophet/), [Anomaly Transformer](https://github.com/thuml/Anomaly-Transformer)
</td>

</tr>



<tr>

<td>conversational AI  </td>
<td>

+ [NeMO](https://github.com/NVIDIA/NeMo), [SpeechRecognition](https://github.com/Uberi/speech_recognition)

</td>

</tr>



<tr>

<td>neural machine translation
 </td>
<td>

+ [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py)
</td>

</tr>



<tr>

<td>voice assistance</td>
<td>

+ [sepia](https://sepia-framework.github.io/), [deepvoiceconversation](https://github.com/andabi/deep-voice-conversion) (voice style transfer)

</td>

</tr>



<tr>

<td>annotation</td>
<td>

+ [doccano](https://github.com/doccano/doccano)

</td>

</tr>



<tr>

<td>CTR</td>
<td>

+ [deepCTR](https://github.com/shenweichen/DeepCTR)

</td>

</tr>


<tr>

<td>extra</td>
<td>

+ [vaderSentiment](https://github.com/cjhutto/vaderSentiment) (sentiment analysis), [gensim](https://github.com/RaRe-Technologies/gensim), [pydub](https://github.com/jiaaro/pydub), [big list of naughty strings](https://github.com/minimaxir/big-list-of-naughty-strings), [snips-nlu](https://github.com/snipsco/snips-nlu), [english words](https://github.com/dwyl/english-words), [vocal-remover](https://github.com/Anjok07/ultimatevocalremovergui).

</td>

</tr>
</table>


# ✤ data visualization:

This [list1](https://github.com/javierluraschi/awesome-dataviz), [list2](https://github.com/topics/data-visualization) has most of the data viz
libraries but i'll list a few which will be relevant for our use cases.

✤ data visualization:
+ [deck.gl](https://github.com/visgl/deck.gl) : [deck.gl](http://deck.gl/) is designed to simplify
high-performance, WebGL-based visualization of large
data sets. Check out these [use cases](https://deck.gl/showcase).
+ [streetscape.gl](https://streetscape.gl/) : [streetscape.gl](http://streetscape.gl/) is a toolkit for
visualizing autonomous and robotics data in the XVIZ
protocol. It is built on top of React and Uber’s
WebGL-powered visualization frameworks. Check this
[demo](https://avs.auto/demo/).
+ [kepler.gl](https://kepler.gl/demo/sfcontour) : github/[Kepler.gl](https://github.com/keplergl/kepler.gl) is a powerful web-based
geospatial data analysis tool. Built on a high
performance rendering engine and designed for
large-scale data sets. [kepler.gl](http://kepler.gl/) is made from [deck.gl](http://deck.gl/).
+ [sanddance](https://microsoft.github.io/SandDance/app/) : github/[SandDance](https://github.com/Microsoft/SandDance) helps you find
insights about your data with unit visualizations and
smooth animated transitions. It uses [deck.gl](http://deck.gl/) to render
chart layouts described with Vega.
+ [flowmapblue](https://github.com/FlowmapBlue/FlowmapBlue) : FlowmapBlue is a free tool for
representing aggregated numbers of movements
between geographic locations as flow maps. It is used
to visualize urban mobility, commuting behavior, bus,
subway and air travels, bicycle sharing, human and
bird migration, refugee flows, freight transportation,
trade, supply chains, scientific collaboration,
epidemiological and historical data and many other
topics.
+ [cartodb](https://github.com/CartoDB/cartodb) : With CARTO, you can upload your
geospatial data (Shapefiles, GeoJSON, etc) using a
web form and then make it public or private. After it is
uploaded, you can visualize it in a dataset or on a map,
search it using SQL, and apply map styles using
CartoCSS.
+ [cesiumJS](https://github.com/CesiumGS/cesium): An open-source JavaScript library for
world-class 3D globes and maps.
+ [Alibaba L7](https://github.com/antvis/L7) & [L7plot](https://github.com/antvis/L7Plot) : Large-scale WebGL-powered
Geospatial Data Visualization analysis engine. L7plot
is a large-scale geospatial visualization chart library.
+ [datamaps](https://github.com/markmarkoh/datamaps): Customizable SVG map visualizations for
the web in a single Javascript file using D3.js

✤ GIS python libraries:
+ [geopandas](https://github.com/geopandas/geopandas) : python tools for geographic data
+ [RSGISlib](https://github.com/remotesensinginfo/rsgislib) : The Remote Sensing and GIS software
library (RSGISLib) is a collection of tools for
processing remote sensing and GIS datasets.
+ [ipyleaflet](https://github.com/jupyter-widgets/ipyleaflet) : If you want to create interactive maps,
ipyleaflet is a fusion of Jupyter notebook and Leaflet.
You can control an assortment of customizations like
loading basemaps, geojson, and widgets.
+ [geemap](https://github.com/giswqs/geemap) : A Python package for interactive mapping
with Google Earth Engine, ipyleaflet, and ipywidgets.
+ [lidar](https://github.com/giswqs/lidar) : lidar is a Python package for delineating the
nested hierarchy of surface depressions in digital
elevation models (DEMs). It is particularly useful for
analyzing high-resolution topographic data, such as
DEMs derived from Light Detection and Ranging
(LiDAR) data.
+ [FOLIUM](https://github.com/python-visualization/folium) : Folium builds on the data wrangling
strengths of the Python ecosystem and the mapping
strengths of the Leaflet.js library. Manipulate your data
in Python, then visualize it in a Leaflet map via folium
+ [geoplot](https://residentmario.github.io/geoplot/index.html) : geoplot is a high-level Python geospatial
plotting library. It’s an extension to cartopy and
matplotlib which makes mapping easy: like seaborn
for geospatial.

✤ ml model visualization:
+ [NETRON](https://github.com/lutzroeder/netron) : Netron is a viewer for neural network,
deep learning and machine learning models.
+ cnn model structure summary with this [code](https://www.kaggle.com/getting-started/195413).
Tools to Design or Visualize Architecture of Neural
Network : [repo](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network) is a good list but i'll list down the few
essentials.
+ [Tensorboard](https://www.tensorflow.org/tensorboard) : TensorFlow visualization toolkit.
+ [PyTorchViz](https://github.com/szagoruyko/pytorchviz) : PyTorch visualization kit.
+ [visualkeras](https://github.com/paulgavrikov/visualkeras) : Visualkeras is a Python package to help
visualize Keras (either standalone or included in
TensorFlow) neural network architectures. The
[keras.utils.vis_utils](https://keras.io/api/utils/model_plotting_utils/) provides utility functions to plot a
Keras model using Graphviz


##  Essential libraries:

<table>
<tr>
<th>Heading</th>
<th>Libraries</th>
</tr>
<tr>
<td>toolbox</td>
<td>y</td>
</tr>


<tr>
<td>web crawling / parse</td>
<td>y</td>
</tr>


<tr>
<td>data</td>
<td>y</td>
</tr>


<tr>
<td>data pipeline / data science</td>
<td>y</td>
</tr>


<tr>
<td>databases</td>
<td>y</td>
</tr>


<tr>
<td>Streaming & stream processing</td>
<td>y</td>
</tr>

<tr>
<td>API</td>
<td>y</td>
</tr>


<tr>
<td>notification</td>
<td>y</td>
</tr>


<tr>
<td>csv - excel - json</td>
<td>y</td>
</tr>


<tr>
<td>recommenders</td>
<td>y</td>
</tr>


<tr>
<td>Documentation/ present
</td>
<td>y</td>
</tr>


<tr>
<td>home automation & IOT / terminal</td>
<td>y</td>
</tr>


<tr>
<td>Tracking & monitoring</td>
<td>y</td>
</tr>


<tr>
<td>networking</td>
<td>y</td>
</tr>


<tr>
<td>automation</td>
<td>y</td>
</tr>


<tr>
<td>testing</td>
<td>y</td>
</tr>


<tr>
<td>GUI</td>
<td>y</td>
</tr>


<tr>
<td>search</td>
<td>y</td>
</tr>


<tr>
<td>pdf</td>
<td>y</td>
</tr>


<tr>
<td>debug</td>
<td>y</td>
</tr>


<tr>
<td>robotics</td>
<td>y</td>
</tr>


<tr>
<td>video conf</td>
<td>y</td>
</tr>


<tr>
<td>security</td>
<td>y</td>
</tr>


<tr>
<td>extra</td>
<td>y</td>
</tr>
</table>

Extra libraries: 

{

[manim](https://github.com/3b1b/manim), [3b1b videos](https://github.com/3b1b/videos), [scientific visualization book](https://github.com/rougier/scientific-visualization-book), [bottles](https://github.com/bottlesdevs/Bottles),
[dash](https://github.com/plotly/dash), [ggpy](https://github.com/yhat/ggpy), [Lenia](https://github.com/Chakazul/Lenia),
[cartography](https://github.com/lyft/cartography), [Pywonderland](https://github.com/neozhaoliang/pywonderland),
[altair](https://github.com/altair-viz/altair), [yellowbrick](https://github.com/DistrictDataLabs/yellowbrick),
[shapely](https://github.com/shapely/shapely), [orange3](https://github.com/biolab/orange3),
[science plots](https://github.com/garrettj403/SciencePlots), [flask_jsondash](https://github.com/christabor/flask_jsondash), [BLOOM](https://bigscience.huggingface.co/blog/bloom), [whisper](https://openai.com/blog/whisper/)


}

> [caliban](https://github.com/google/caliban) : Google Caliban is a tool that helps
researchers launch and track their numerical
experiments in an isolated, reproducible computing
environment.

> [kornia](https://github.com/kornia/kornia) : Kornia is a differentiable computer vision
library for PyTorch. It consists of a set of routines and differentiable modules to solve generic computer
vision problems.

> [intel analytics-zoo](https://github.com/intel-analytics/analytics-zoo) : Analytics Zoo is an open source
Big Data AI platform, and includes the following
features for scaling end-to-end AI to distributed Big
Data:

> [mljar-supervised](https://github.com/mljar/mljar-supervised) : The mljar-supervised is an
Automated Machine Learning Python package that
works with tabular data. It abstracts the common way
to preprocess the data, construct the machine learning
models, and perform hyper-parameters tuning to find
the best model. Automatic Exploratory Data Analysis.

> [deepdetect](https://github.com/jolibrain/deepdetect#main-features) : open source ai platform written in c++
with readily available API, algorithms, models etc.
supports state of the art algorithms - clustering with
[t-SNE](https://github.com/DmitryUlyanov/Multicore-TSNE), similarity search with [annoy](https://github.com/spotify/annoy/), [FAISS](https://github.com/facebookresearch/faiss). . templates
for the most useful neural architectures (e.g.
Googlenet, Alexnet, ResNet, convnet, character-based
convnet, mlp, logistic regression, SSD, DeepLab,
PSPNet, U-Net, CRNN, ShuffleNet, SqueezeNet,
MobileNet, RefineDet, VOVNet, ...)

> RL FRAMEWORKS:
+ [dopamine](https://github.com/google/dopamine) : Deep Reinforcement Learning
Framework
+ [deepmind lab](https://github.com/deepmind/lab) : 3d env for DRL
  
> [predictionio](https://github.com/apache/predictionio): Apache predictionio supports event
collection, deployment of algorithms, evaluation,
querying predictive results via REST APIs. It is based
on scalable open source services like Hadoop, HBase
(and other DBs), Elasticsearch, Spark and implements
what is called a Lambda Architecture.

> [detectron2](https://github.com/facebookresearch/detectron2): facebook's state of the art vision
algorithm platform.

> [tflearn](https://github.com/tflearn/tflearn) : high level API over tensorflow

> [faceswap](https://github.com/deepfakes/faceswap#deepfakesfaceswap) : open source deep fake library & also
image manipulation libraries - [pix2style2pix](https://github.com/eladrich/pixel2style2pixel), [avatarify](https://github.com/alievk/avatarify-python), [neural photo editor](https://github.com/ajbrock/Neural-Photo-Editor), [GANimation](https://github.com/albertpumarola/GANimation).

> [waveglow](https://github.com/NVIDIA/waveglow): NVIDIA waveglow for audio & speech
synthesis

> [neural-enhance](https://github.com/alexjc/neural-enhance): neural enhance is super resolution
for frames

> [real-time voice cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning): audio deep fakes, also
[mockingbird](https://github.com/babysor/MockingBird).

> [fasttext](https://github.com/facebookresearch/fastText): facebook fasttext allows users to efficiently learn word representation and text classification.

> [deOldify](https://github.com/jantic/DeOldify): colorize, restore, and give new life to old
images and film footage also [microsoft's repo](https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life).

> [NeuralTalk2](https://github.com/karpathy/neuraltalk2) : is used to describe images and videos
with sentences using Multimodal Recurrent Neural
Network built on Python+numpy.

> [face-recognition](https://github.com/ageitgey/face_recognition): real time face recognition. also [yolo-v5](https://github.com/ultralytics/yolov5).

> [U GATIT](https://github.com/taki0112/UGATIT): image to anime.

> [srez](https://github.com/david-gpu/srez) : Image super-resolution using deep learning
can upscale a 16x16 input image by a 4X factor,
resulting in a 64x64 image.

> [TecoGAN](https://github.com/thunil/TecoGAN): video super resolution.

> [CMU open-pose](https://github.com/CMU-Perceptual-Computing-Lab/openpose): first real-time multi-person system
to jointly detect human body, hand, facial, and foot
keypoints (in total 135 keypoints) on single images,
also [pose-animator](https://github.com/yemount/pose-animator/).

> [spaCy](https://github.com/explosion/spaCy) : industrial grade NLP in python.

> [server](https://github.com/triton-inference-server/server): optimized cloud and edge inferencing
solutions.

> [back ground matting v2](https://github.com/PeterL1n/BackgroundMattingV2): real time background
change

> [skyAR](https://github.com/jiupinjia/SkyAR): sky replacement with [cycleGAN](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

> [txtai](https://github.com/neuml/txtai): AI powered semantic search applications.

> [Open Neural Network Exchange](https://github.com/onnx/onnx) (ONNX) : is an open
ecosystem that empowers AI developers to choose
the right tools as their project evolves. They have a lot of [models](https://github.com/onnx/models) as well. also [onnxruntime](https://github.com/microsoft/onnxruntime).

> [open-cog](https://github.com/opencog/opencog) : works towards AGI and integrates AI
algorithms and systems into humanoid robotic
systems. Most of the activity within this particular
repo has focused on integrating natural language chat,
common-sense reasoning, assorted learning
algorithms, and motor control of humanoid robots.

> [prophet](https://github.com/facebook/prophet): facebook's prophet is a tool for producing
high quality forecasts for time series data that has
multiple seasonality with linear or non-linear growth.

> [Apache SystemDS](https://github.com/apache/systemds): SystemDS is an open source ML
system for the end-to-end data science lifecycle from
data integration, cleaning, and feature engineering,
over efficient, local and distributed ML model training, to deployment and serving.

> [AIF360](https://github.com/Trusted-AI/AIF360) : A comprehensive set of fairness metrics for
datasets and machine learning models, explanations
for these metrics, and algorithms to mitigate bias in
datasets and models.

> [tpot](https://github.com/EpistasisLab/tpot) : A Python Automated Machine Learning tool
that optimizes machine learning pipelines using
genetic programming or a data science assistant for
pipeline generation.

> [feature-tool](https://github.com/alteryx/featuretools) : Feature tools automatically create
features from temporal and relational datasets.

> [auto-sklearn](https://github.com/automl/auto-sklearn) : is an automated machine learning
toolkit and a drop-in replacement for a scikit-learn
estimator.

> [skorch](https://github.com/skorch-dev/skorch) : A scikit-learn compatible neural network
library that wraps PyTorch.

> [streamlit](https://github.com/streamlit/streamlit) : The fastest way to build data apps in
Python also this repo [awesome-ml](https://github.com/josephmisiti/awesome-machine-learning) covers a wide range of
topics.

> [optuna](https://github.com/optuna/optuna) : Optuna is an automatic hyperparameter
optimization software framework, particularly
designed for machine learning.

> [shap](https://github.com/slundberg/shap) : A game theoretic approach to explain the
output of any machine learning model.

> [pandas-profiling](https://github.com/ydataai/pandas-profiling) : Create HTML profiling reports from pandas DataFrame objects.