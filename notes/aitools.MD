## AI tools and Open Source Libraries

Open Source Python Libraries
Github [repo search readme](https://docs.github.com/en/enterprise-server@3.4/search-github/getting-started-with-searching-on-github/understanding-the-search-syntax) ---> [Github](https://github.com/search?l=Python&q=stars%3A%3E1000&type=Repositories).

Here is a list of all python libraries beyond 2k stars, updated in 25/09/2022




PYTHON LIBRARIES:


<table style="width:100%" >
<tr>
<th>
<p>Heading
</p>
</th>
<th>
<p>Libraries
</p></th>
</tr>
<tr>

<td>
Python 
</td>

<td>

+ [awesome-python](https://github.com/vinta/awesome-python#readme), [The Algorithms/Python](https://github.com/TheAlgorithms/Python), [awesome-ml/python](https://github.com/josephmisiti/awesome-machine-learning#python), [ctci](https://github.com/careercup/CtCI-6th-Edition-Python), [python pattern](https://github.com/faif/python-patterns), [py-cheatsheet](https://github.com/gto76/python-cheatsheet), [py-examples](https://github.com/geekcomputers/Python),
[interactive-coding-challenges](https://github.com/donnemartin/interactive-coding-challenges), [python-robotics](https://github.com/AtsushiSakai/PythonRobotics), [data-structure & algorithm](https://github.com/keon/algorithms), [pysheet](https://github.com/crazyguitar/pysheeet), [cookiecutter](https://github.com/cookiecutter/cookiecutter).
</td>

</tr>


<tr>

<td>
pylibs
</td>

<td>

+ [python-fire](https://github.com/google/python-fire), [faker](https://github.com/joke2k/faker) & [mimesis](https://github.com/lk-geimfari/mimesis), [sh](https://github.com/amoffat/sh), [marshmallow](https://github.com/marshmallow-code/marshmallow), [boltons](https://github.com/mahmoud/boltons), [py-github](https://github.com/PyGithub/PyGithub), [py-dotenv](https://github.com/theskumar/python-dotenv), [jedi](https://github.com/davidhalter/jedi), [jedi-vim](https://github.com/davidhalter/jedi-vim), [setup.py](https://github.com/navdeep-G/setup.py), [trio](https://github.com/python-trio/trio), [pycodestyle](https://github.com/PyCQA/pycodestyle), [pyinstrument](https://github.com/joerick/pyinstrument), [pathplanning](https://github.com/zhm-real/PathPlanning), [pidcat](https://github.com/JakeWharton/pidcat), [augly](https://github.com/facebookresearch/AugLy) (data aug), [pipreqs](https://github.com/bndr/pipreqs) ( or pip
freeze > req.txt), [apscheduler](https://github.com/agronholm/apscheduler) & [huey](https://github.com/coleifer/huey) (task schedule), [attrs](https://github.com/python-attrs/attrs), [bandit](https://github.com/PyCQA/bandit), [tablib](https://github.com/jazzband/tablib), [autopep8](https://github.com/hhatto/autopep8), [better_exception](https://github.com/Qix-/better-exceptions), [tenacity](https://github.com/jd/tenacity), [py-sorted-containers](https://github.com/grantjenks/python-sortedcontainers),
[viztracer](https://github.com/gaogaotiantian/viztracer), [memray](https://github.com/bloomberg/memray), [ryven](https://github.com/leon-thomm/Ryven), [black](https://github.com/psf/black), [monkeytype](https://github.com/Instagram/MonkeyType), [pytype](https://github.com/google/pytype), [vprof](https://github.com/nvdv/vprof), [cookie-cutter-py-package](https://github.com/audreyfeldroy/cookiecutter-pypackage), [coconut](https://github.com/evhub/coconut) (functional programming), [pampy](https://github.com/santinic/pampy).

</td>
</tr>


<tr>

<td>
essentials libraries
</td>

<td>

+ [numpy](https://github.com/numpy/numpy), [pandas](https://github.com/pandas-dev/pandas), [matplotlib](https://github.com/matplotlib/matplotlib), [scipy](https://github.com/scipy/scipy), [scikit-learn](https://github.com/scikit-learn/scikit-learn) | [blaze](https://github.com/blaze/blaze) (numpy, pandas for big data), [cupy](https://github.com/cupy/cupy) (NumPy & SciPy for GPU).
</td>
</tr>


<tr>

<td>
ml extra
</td>

<td>

+ [transfer learning](https://github.com/jindongwang/transferlearning#7datasets-and-benchmarks-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C), [docker-stacks](https://github.com/jupyter/docker-stacks), [hyper-opt](https://github.com/hyperopt/hyperopt), [feature-tools](https://github.com/alteryx/featuretools), [einops](https://github.com/arogozhnikov/einops), [cog](https://github.com/replicate/cog), [floydhub](https://github.com/floydhub/dl-docker), [FEAST](https://github.com/feast-dev/feast), [causal-ml](https://github.com/uber/causalml), [scikit-opt](https://github.com/guofei9987/scikit-opt), [anomaly detect](https://github.com/yzhao062/anomaly-detection-resources), [Bayesian Optimization](https://github.com/fmfn/BayesianOptimization).

</td>
</tr>

<tr>

<td>
tf / (PyTorch )
</td>

<td>

+ [tensorpack](https://github.com/tensorpack/tensorpack), [hub](https://github.com/tensorflow/hub) (transfer learning), [pyg-team](https://github.com/pyg-team/pytorch_geometric), [pretrained-models](https://github.com/Cadene/pretrained-models.pytorch), [minGPT](https://github.com/karpathy/minGPT), [tensorboardX](https://github.com/lanpa/tensorboardX), [pyro](https://github.com/pyro-ppl/pyro), [CNNviZ](https://github.com/utkuozbulak/pytorch-cnn-visualizations), [External Attention](https://github.com/xmu-xiaoma666/External-Attention-pytorch), [segmentation-models](https://github.com/qubvel/segmentation_models.pytorch), [torchdiffeq](https://github.com/rtqichen/torchdiffeq), [ignite](https://github.com/pytorch/ignite), [gpytorch](https://github.com/cornellius-gp/gpytorch), [catalyst](https://github.com/catalyst-team/catalyst) (for R&D), [big-graph](https://github.com/facebookresearch/PyTorch-BigGraph), [VAE](https://github.com/AntixK/PyTorch-VAE), [metaseq](https://github.com/facebookresearch/metaseq), [THOP](https://github.com/Lyken17/pytorch-OpCounter), [captum](https://github.com/pytorch/captum), [Imaginaire](https://github.com/NVlabs/imaginaire), [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt), [pytorch.summary()](https://github.com/sksq96/pytorch-summary), [person-reid](https://github.com/KaiyangZhou/deep-person-reid).
</td>
</tr>


<tr>

<td>
ML framework: 
</td>

<td>

+ [autogluon](https://github.com/awslabs/autogluon), [jax](https://github.com/google/jax), [sanic](https://github.com/sanic-org/sanic), [falcon](https://github.com/falconry/falcon), [ludwig](https://github.com/ludwig-ai/ludwig), [kedro](https://github.com/kedro-org/kedro), [trax](https://github.com/google/trax), [deepo](https://github.com/ufoym/deepo), [ivy](https://github.com/unifyai/ivy), [chainer](https://github.com/chainer/chainer), [sktime](https://github.com/alan-turing-institute/sktime) & [merlion](https://github.com/salesforce/Merlion) (time series), [pocketflow](https://github.com/Tencent/PocketFlow), [igel](https://github.com/nidhaloff/igel) (no code), [flax](https://github.com/google/flax).

</td>
</tr>

</table>

Reinforcement Learning libraries:

+ [baselines](https://github.com/openai/baselines), [gym](https://github.com/openai/gym), [mujoco](https://github.com/deepmind/mujoco), [tianshou](https://github.com/thu-ml/tianshou), [DRL-PyTorch](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch), [dm_control](https://github.com/deepmind/dm_control), [PARL](https://github.com/PaddlePaddle/PARL), [ReAgent tensorforce](https://github.com/facebookresearch/ReAgent).

MLOPs / Distributed ML libraries:

+ [horovod](https://github.com/horovod/horovod), [Deep Speed](https://github.com/microsoft/DeepSpeed), [modin](https://github.com/modin-project/modin), [bentoml](https://github.com/bentoml/BentoML), [apex](https://github.com/NVIDIA/apex), [dask](https://github.com/dask/dask), [colossal-AI](https://github.com/hpcaitech/ColossalAI), [composer](https://github.com/mosaicml/composer), [mlflow](https://github.com/mlflow/mlflow), [lightning](https://github.com/Lightning-AI/lightning), [airflow](https://github.com/apache/airflow), [deap](https://github.com/DEAP/deap) (distributed evolutionary algorithms), [ray](https://github.com/ray-project/ray), [mars](https://github.com/mars-project/mars), [tensorflowonspark](https://github.com/yahoo/TensorFlowOnSpark), [sonnet](https://github.com/deepmind/sonnet), [celery](https://github.com/celery/celery), [pandarallel](https://github.com/nalepae/pandarallel), [polyaxon](https://github.com/polyaxon/polyaxon), [hummingbird](https://github.com/microsoft/hummingbird), [nni](https://github.com/microsoft/nni) , [byteps](https://github.com/bytedance/byteps), [vaex](https://github.com/vaexio/vaex), [clearml](https://github.com/allegroai/clearml), [tvm](https://github.com/apache/tvm), [st2](https://github.com/StackStorm/st2), [jina](https://github.com/jina-ai/jina) , [accelerate](https://github.com/huggingface/accelerate).

Computer Vision / Visualization Libraries:

<table>
<tr>

<td>
CV Toolbox
</td>

<td>

+ [mmlab](https://github.com/open-mmlab/mmcv), [gluon-cv](https://github.com/dmlc/gluon-cv), [slowfast](https://github.com/facebookresearch/SlowFast), [grad-cam](https://github.com/jacobgil/pytorch-grad-cam).
 
</td>
</tr>


<tr>

<td>
Object Detection
</td>

<td>

+ [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX), [detr](https://github.com/facebookresearch/detr), [ImageAI](https://github.com/OlafenwaMoses/ImageAI#customprediction), [EfficientNet](https://github.com/lukemelas/EfficientNet-PyTorch), [CenterNet](https://github.com/xingyizhou/CenterNet), [frigate](https://github.com/blakeblackshear/frigate), [nanodet](https://github.com/RangiLyu/nanodet) (lightwight), [obj-detect-metric](https://github.com/rafaelpadilla/review_object_detection_metrics), [ConvNeXt](https://github.com/facebookresearch/ConvNeXt), [YoloV7](https://github.com/jinfagang/yolov7_d2), [ByteTrack](https://github.com/ifzhang/ByteTrack), [mmtracking](https://github.com/open-mmlab/mmtracking).
 
</td>
</tr>



<tr>

<td>
Text-to-Image 
</td>

<td>

+ [PyTorch] [DALL-E](https://github.com/lucidrains/DALLE-pytorch), [DALLE2](https://github.com/lucidrains/DALLE2-pytorch), [dalle-mini](https://github.com/borisdayma/dalle-mini), [stable diffusion](https://github.com/CompVis/stable-diffusion) ([lexica.art](https://lexica.art/)), [Imagen](https://github.com/lucidrains/imagen-pytorch), [stable diffusion_webui](https://github.com/sd-webui/stable-diffusion-webui).
 
</td>
</tr>



<tr>

<td>
Multilingual OCR &QR
</td>

<td>

+ [Paddle Paddle](https://github.com/PaddlePaddle/PaddleOCR), [EasyOCR](https://github.com/JaidedAI/EasyOCR), [amazing-qr](https://github.com/x-hw/amazing-qr), [OCR PDF](https://github.com/ocrmypdf/OCRmyPDF).
 
</td>
</tr>


<tr>

<td>
Image Augmentation
</td>

<td>

+  [imgaug](https://github.com/aleju/imgaug), [albumentations](https://github.com/albumentations-team/albumentations).
 
</td>
</tr>


<tr>

<td>
Upscale 
</td>

<td>

+ [video2x](https://github.com/k4yt3x/video2x).
 
</td>
</tr>


<tr>

<td>
Pose Detection
</td>

<td>

+ [alphapose](https://github.com/MVIG-SJTU/AlphaPose), [mmskeleton](https://github.com/open-mmlab/mmskeleton), [videopose3D](https://github.com/facebookresearch/VideoPose3D), [DeepLabCut](https://github.com/DeepLabCut/DeepLabCut).
 
</td>
</tr>


<tr>

<td>
Annotation tool 
</td>

<td>

+ [labelme](https://github.com/wkentaro/labelme), [labelmg](https://github.com/heartexlabs/labelImg), [label-studio](https://github.com/heartexlabs/label-studio).
 
</td>
</tr>


<tr>

<td>
Deep Fakes 
</td>

<td>

+ [DeepFaceLive](https://github.com/iperov/DeepFaceLive), [PaddleGAN](https://github.com/PaddlePaddle/PaddleGAN), [dot](https://github.com/sensity-ai/dot) ( deepfakes offensive toolkit).
 
</td>
</tr>


<tr>

<td>
Segmentation / Inpainting / Matting
</td>

<td>

+ [PaddleSeg](https://github.com/PaddlePaddle/PaddleSeg), [3D photo inpainting, video matting](https://github.com/vt-vl-lab/3d-photo-inpainting), [bg-matting-v2](https://github.com/PeterL1n/BackgroundMattingV2), [yolact](https://github.com/dbolya/yolact), [semantic seg](https://github.com/CSAILVision/semantic-segmentation-pytorch), [Super SloMo](https://github.com/avinashpaliwal/Super-SloMo).

 
</td>
</tr>


<tr>

<td>
Face Detection
</td>

<td>

+ [face.evoLVe](https://github.com/ZhaoJ9014/face.evoLVe), [InsightFace](https://github.com/deepinsight/insightface), [face-alignment](https://github.com/1adrianb/face-alignment), [PRNET](https://github.com/YadiraF/PRNet), [fawkes](https://github.com/Shawn-Shan/fawkes) (privacy preserving), [deepface](https://github.com/serengil/deepface), [howdy](https://github.com/boltgolt/howdy).

 
</td>
</tr>


<tr>

<td>
WebML
</td>

<td>

+ [gradio](https://github.com/gradio-app/gradio) (UI for ML model).
 
</td>
</tr>


<tr>

<td>
3D data processing & reconstruction
</td>

<td>

+ [Open3D](https://github.com/isl-org/Open3D), [meshroom](https://github.com/alicevision/meshroom), [PyTorch3D](https://github.com/facebookresearch/pytorch3d), [mmlab3d](https://github.com/open-mmlab/mmdetection3d), [OpenPCDet](https://github.com/open-mmlab/OpenPCDet), [OpenSfm](https://github.com/mapillary/OpenSfM), [kaolin](https://github.com/NVIDIAGameWorks/kaolin), [ODM](https://github.com/OpenDroneMap/ODM), [PointNet](https://github.com/charlesq34/pointnet), [3D-Resnets](https://github.com/kenshohara/3D-ResNets-PyTorch).
 
</td>
</tr>


<tr>

<td>
fun plugins
</td>

<td>

+ [avatarify-python](https://github.com/alievk/avatarify-python), [word cloud](https://github.com/amueller/word_cloud), [pywal](https://github.com/dylanaraps/pywal), [tiler](https://github.com/nuno-faria/tiler), [learning to see in dark](https://github.com/cchen156/Learning-to-See-in-the-Dark), [rembg](https://github.com/danielgatis/rembg), [imagededup](https://github.com/idealo/imagededup) (find duplicate images), [imutils](https://github.com/PyImageSearch/imutils) (image operations), [videogrep](https://github.com/antiboredom/videogrep), [NeRF](https://github.com/yenchenlin/nerf-pytorch), [LEGOFY](https://github.com/JuanPotato/Legofy), [discoart](https://github.com/jina-ai/discoart), [image/analogies](https://github.com/awentzonline/image-analogies).
 
</td>
</tr>

<tr>

<td>
Big Data visualization
</td>

<td>

+ [visdom](https://github.com/fossasia/visdom) (LIVE experiments), [redash](https://github.com/getredash/redash) (from Datalake), [great_expectations](https://github.com/great-expectations/great_expectations), [folium](https://github.com/python-visualization/folium), [visidata](https://github.com/saulpw/visidata), [lux](https://github.com/lux-org/lux) (pandas dataframe).
 
</td>
</tr>


<tr>

<td>
Extra
</td>

<td>

+ [diagrams](https://github.com/mingrammer/diagrams) (vis cloud architecture),  [openpilot](https://github.com/commaai/openpilot), [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN), [pifuhd](https://github.com/facebookresearch/pifuhd), [pix2pixhd](https://github.com/NVIDIA/pix2pixHD), [Neural-style](https://github.com/anishathalye/neural-style), [tensorflow-GAN](https://github.com/hwalsuklee/tensorflow-generative-model-collections),  [eht-imaging](https://github.com/NVIDIA/pix2pixHD), [efficient-ai-backbone](https://github.com/huawei-noah/Efficient-AI-Backbones), [bandai-namco motion dataset](https://github.com/BandaiNamcoResearchInc/Bandai-Namco-Research-Motiondataset), [MONAI](https://github.com/Project-MONAI/MONAI).

 
</td>
</tr>

</table>

Natural Language Processing (NLP) libraries:

<table>
<tr>

<th>Heading</th>
<th>Libraries</th>

</tr>
<tr>

<td>NLP toolkit</td>
<td>

+ [funNLP](https://github.com/fighting41love/funNLP), [NLP Progress](https://github.com/sebastianruder/NLP-progress), [flair](https://github.com/flairNLP/flair), [pytext](https://github.com/facebookresearch/pytext), [allenNLP](https://github.com/allenai/allennlp), [nltk](https://github.com/nltk/nltk), [haystack](https://github.com/deepset-ai/haystack), [ParlAI](https://github.com/facebookresearch/ParlAI), [fairseq](https://github.com/facebookresearch/fairseq), [ERNIE](https://github.com/PaddlePaddle/ERNIE), [stanza](https://github.com/stanfordnlp/stanza), [speech brain](https://github.com/speechbrain/speechbrain), [OpenNRE](https://github.com/thunlp/OpenNRE).

</td>

</tr>


<tr>

<td>
audio analysis
</td>
<td>

+ [PyAudioAnalysis](https://github.com/tyiannak/pyAudioAnalysis), [espnet](https://github.com/espnet/espnet) (end2endspeech processing), [librosa](https://github.com/librosa/librosa)

</td>

</tr>


<tr>

<td>
chatbot
</td>
<td>

+ [errbot](https://github.com/errbotio/errbot), [wav2lip](https://github.com/Rudrabha/Wav2Lip) (speech2lip)

</td>

</tr>


<tr>

<td>text2speech</td>
<td>

+ [TTS](https://github.com/coqui-ai/TTS)
</td>

</tr>


<tr>

<td>time series </td>
<td>

+ [darts](https://github.com/unit8co/darts), [kats](https://github.com/facebookresearch/Kats), [prophet](https://facebook.github.io/prophet/), [Anomaly Transformer](https://github.com/thuml/Anomaly-Transformer)
</td>

</tr>



<tr>

<td>conversational AI  </td>
<td>

+ [NeMO](https://github.com/NVIDIA/NeMo), [SpeechRecognition](https://github.com/Uberi/speech_recognition)

</td>

</tr>



<tr>

<td>neural machine translation
 </td>
<td>

+ [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py)
</td>

</tr>



<tr>

<td>voice assistance</td>
<td>

+ [sepia](https://sepia-framework.github.io/), [deepvoiceconversation](https://github.com/andabi/deep-voice-conversion) (voice style transfer)

</td>

</tr>



<tr>

<td>annotation</td>
<td>

+ [doccano](https://github.com/doccano/doccano)

</td>

</tr>



<tr>

<td>CTR</td>
<td>

+ [deepCTR](https://github.com/shenweichen/DeepCTR)

</td>

</tr>


<tr>

<td>extra</td>
<td>

+ [vaderSentiment](https://github.com/cjhutto/vaderSentiment) (sentiment analysis), [gensim](https://github.com/RaRe-Technologies/gensim), [pydub](https://github.com/jiaaro/pydub), [big list of naughty strings](https://github.com/minimaxir/big-list-of-naughty-strings), [snips-nlu](https://github.com/snipsco/snips-nlu), [english words](https://github.com/dwyl/english-words), [vocal-remover](https://github.com/Anjok07/ultimatevocalremovergui).

</td>

</tr>
</table>

