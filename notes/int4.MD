# Zeus: Understanding and Optimizing GPU Energy Consumption of DNN Training

[ paper : [web](https://www.usenix.org/conference/nsdi23/presentation/you), [pdf](https://www.usenix.org/system/files/nsdi23-you.pdf) ] | [ [video](https://youtu.be/aZoD-jgO3fE?si=WhcxloaeZDnFAgvo) ]


<p class="ex1" align="justify" style="padding: 5px 5px 5px 5px">
Abstract:  Training deep neural networks (DNNs) is becoming increasingly more resource- and energy-intensive every year. Unfortunately, existing works primarily focus on optimizing DNN training for faster completion, often without considering the impact on energy efficiency.
In this paper, we observe that common practices to improve training performance can often lead to inefficient energy usage. More importantly, we demonstrate that there is a tradeoff between energy consumption and performance optimization. To this end, we propose Zeus, an optimization framework to navigate this tradeoff by automatically finding optimal job- and GPU-level configurations for recurring DNN training jobs. Zeus uses an online exploration-exploitation approach in conjunction with just-in-time energy profiling, averting the need for expensive offline measurements, while adapting to data drifts over time. Our evaluation shows that Zeus can improve the energy efficiency of DNN training by 15.3%â€“75.8% for diverse workloads.

</p>

Deep neural networks (DNNs) have been widely adopted in fields like computer vision, natural language processing, personalized recommendation, and speech recognition. They are mainly trained using clusters of powerful GPUs, which increases energy demand. For example, training the GPT-3 model consumes 1,287 MWh, equivalent to 120 years of electricity for an average U.S. household. Despite this, most research overlooks energy efficiency in DNN training. Common optimization practices, such as using large batch sizes for higher throughput, can lead to inefficient energy use. Our analysis shows that choosing the right batch size and GPU power limit can reduce energy consumption by 23.8%-74.7% across various workloads. However, there's a tradeoff between energy consumption and training time. We identify that all optimal configurations offer energy reductions compared to using maximum batch size and power limit, but the relationship between energy savings and training time increase is often non-linear. Thus, we must find ways to balance energy consumption and training time automatically.