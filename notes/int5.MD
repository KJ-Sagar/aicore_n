# Energy Time Fairness: Balancing Fair Allocation of Energy and Time for GPU Workloads

[ paper : DOI[10.1145/3583740.3628435](https://www.computer.org/csdl/proceedings-article/sec/2023/012300a053/1UlmMhdN732) ]


<p class="ex1" align="justify" style="padding: 5px 5px 5px 5px">
Abstract : Traditionally, multi-tenant cloud and edge platforms use fair-share schedulers to fairly multiplex resources across applications. These schedulers ensure applications receive processing time proportional to a configurable share of the total time. Unfortunately, enforcing time-fairness across applications often violates energy-fairness, such that some applications consume more than their fair share of energy. This occurs because applications either do not fully utilize their resources or operate at a reduced frequency/voltage during their time-slice. The problem is particularly acute for machine learning (ML) applications using GPUs, where model size largely dictates utilization and energy usage. Enforcing energy-fairness is also important since energy is a costly and limited resource. For example, in cloud platforms, energy dominates operating costs and is limited by the power delivery infrastructure, while in edge platforms, energy is often scarce and limited by energy harvesting and battery constraints. To address the problem, we define the notion of Energy-Time Fairness (ETF), which enables a configurable tradeoff between energy and time fairness, and then design a scheduler that enforces it. We show that ETF satisfies many well-accepted fairness properties. ETF and the new tradeoff it offers are important, as some applications, especially ML models, are time/latency-sensitive and others are energy-sensitive. Thus, while enforcing pure energy-fairness starves time/latency-sensitive applications (of time) and enforcing pure time-fairness starves energy-sensitive applications (of energy), ETF is able to mind the gap between the two. We implement an ETF scheduler, and show that it improves fairness by up to 2x, incentivizes energy efficiency, and exposes a configurable knob to operate between energy- and time-fairness.

</p>

`KEYWORDS` : FairShare, Energy-aware, Energy-efficiency, Scheduling, Resource Management

Over the past decade, cloud and edge platforms have significantly reduced the cost of large-scale computing and storage, enabling a variety of applications such as web services, batch processing, machine learning, and mobile augmented reality. This cost reduction is achieved through the efficient sharing of resources among diverse users and applications, increasing utilization and efficiency. This is particularly crucial for high-cost resources like GPUs, which are in high demand due to growing AI workloads. For instance, edge platforms in small autonomous vehicles, such as delivery robots, use shared onboard systems for tasks like obstacle detection and traffic monitoring. However, resource sharing introduces challenges, requiring operators to balance resources across different applications, especially when constrained by limited computational capacity and energy.

Multi-tenant cloud and edge platforms traditionally use fair-share schedulers to allocate server resources equitably among multiple applications. These schedulers ensure each application receives a proportional share of processing time, preventing any application from monopolizing resources or being starved. Over the past three decades, numerous scheduling policies have been developed, such as [Weighted Fair Queuing](https://dl.acm.org/doi/10.1145/75247.75248), [max-min fairness](https://www.jstor.org/stable/3010473), [Start-Time Fair Queueing](https://ieeexplore.ieee.org/document/649569/), [lottery scheduling](https://www.usenix.org/legacy/publications/library/proceedings/osdi/full_papers/waldspurger.pdf), and [Dominant Resource Fairness](https://www.usenix.org/conference/nsdi11/dominant-resource-fairness-fair-allocation-multiple-resource-types). Fair-share scheduling is widely implemented in modern operating systems, hypervisors, batch schedulers, container orchestration platforms, and data-processing platforms like Linux, Xen, VSphere, Slurm, Kubernetes, Spark, and Hadoop.